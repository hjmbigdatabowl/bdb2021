<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Submission • bdb2021</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Submission">
<meta property="og:description" content="bdb2021">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">bdb2021</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">1.0.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/submission.html">Submission</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="submission_files/accessible-code-block-0.0.1/empty-anchor.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Submission</h1>
            
      
      
      <div class="hidden name"><code>submission.Rmd</code></div>

    </div>

    
    
<div id="introduction" class="section level2">
<h2 class="hasAnchor">
<a href="#introduction" class="anchor"></a>Introduction</h2>
<p>Our project aims to measure the ability of defensive backs at performing different aspects of their defensive duties: deterring targets (either by reputation or through good positioning), closing down receivers, and breaking up passes. We do this by fitting four models, two for predicting the probability that a receiver will be targeted on a given play and two for predicting the probability that a pass will be caught, which we then use to aggregate the contributions of defensive backs of the course of the season.</p>
</div>
<div id="modeling-framework" class="section level2">
<h2 class="hasAnchor">
<a href="#modeling-framework" class="anchor"></a>Modeling Framework</h2>
<p>We opted to use XGBoost for all of our models. At a high level, we chose a tree booster for its ability to find complex interactions between predictors, something we anticipated would be necessary for this project. Tree boosting also allows for null values to be present, which helped us divvy up credit in the catch probability models (more on this later). Finally, tree boosting is a relatively simple, easy to tune algorithm that also tends to perform extremely well, as was the case for us.</p>
</div>
<div id="catch-probability" class="section level2">
<h2 class="hasAnchor">
<a href="#catch-probability" class="anchor"></a>Catch Probability</h2>
<p>Our catch probability model has two distinct components: The catch probability at throw time – as in, the chance that the pass is caught at the time the quarterback releases the ball – and the catch probability at arrival time – the chance the pass is caught at the time the ball arrives. These probabilities are clearly distinct, since a lot can happen between throw release and throw arrival. First, we will walk through the features that are used in building each model.</p>
<p>For the throw time model (which we will refer to as the “throw” model) and the arrival time model (the “arrival” model), the most important predictors by variable importance were what we expected entering this project: the distance of the receiver to the closest defender, the position of the receiver in the <span class="math inline">\(y\)</span> direction (i.e. distance from the sideline), the distance of the throw, the position of the football in the <span class="math inline">\(y\)</span> direction at arrival time (this is mostly catching throws to the sideline and throw aways), the velocity of the throw, the velocity and acceleration of the targeted receiver, and a composite receiver skill metric. For the arrival model, we use many of the same features. However, we do not account for the distance of the defenders to the throw vector – which accounts for the ability to break up a pass mid-flight – because the throw has already arrived.</p>
<p>These two models both perform quite well, and far better than random chance. The throw model accurately predicts <span class="math inline">\(74\%\)</span> of all passes, with strong precision (<span class="math inline">\(84\%\)</span>) and recall (<span class="math inline">\(76\%\)</span>), and an AUC of <span class="math inline">\(.81\)</span>. As can be expected, our arrival model outperforms the throw model in all measures - accurately predicting <span class="math inline">\(78\%\)</span> of all passes with a precision of <span class="math inline">\(88\%\)</span>, a recall of <span class="math inline">\(79\%\)</span>, and an AUC of <span class="math inline">\(87\%\)</span>. All of these metrics were calculated on a held out data set not used in model training. Below are plots of the calibration of the predictions of each of the models on the same held out set.</p>
<p> </p>
<div class="figure" style="text-align: center">
<img src="../inst/plots/calplot_t.png" alt="Catch Probability Model Calibration Plots" width="45%" height="45%"><img src="../inst/plots/calplot_a.png" alt="Catch Probability Model Calibration Plots" width="45%" height="45%"><p class="caption">
Catch Probability Model Calibration Plots
</p>
</div>
<p> </p>
<p>We can do a few particularly interesting things with the predictions from these two models in tandem. Namely, we can use the two to calculate marginal effects of the play of the defensive backs. A simple example is as follows: For a given pass attempt, our throw model estimates that there is a <span class="math inline">\(.8\)</span> chance of a catch. By the time that pass arrives, however, our arrival model estimates instead that there is a <span class="math inline">\(.5\)</span> chance of a catch. Ultimately, the play results in a drop. In total, our defense can get credit for <span class="math inline">\(+.8\)</span> drops, but we can break it down into <span class="math inline">\(+.3\)</span> drops worth from closing on the receiver and <span class="math inline">\(+.5\)</span> drops from breaking up the play, based on how the individual components differ. In other words, we subtract the probability of a catch at arrival time from the probability at throw time to get the credit for closing down the receiver, and we subtract the true outcome of the play from the probability of a catch at arrival time to get the credit for breaking up the pass.</p>
<p>The main challenge comes not from calculating the overall credit on the play, but from the distribution of credit <em>among</em> the defenders. In the previous example where we have to credit the defense with <span class="math inline">\(+.8\)</span> drops added, <em>who</em> exactly on the defense do we give that credit to? There are a couple of heuristics that might make sense. One option would be to just split the credit up evenly among the defense, but this would be a bad heuristic because some defenders will have more of an impact on a pass being caught than others, and thus deserve more credit. We might also give all of the credit to the nearest defender, but that would be unfair to players who are within half a yard of the play and are also affecting its outcome, for example, but get no credit. Interestingly, it turns out that we can use the models to engineer the credit each player deserves by seeing how the catch probabilities would change if we magically removed them from the field, which is a better heuristic than both of the previous two. To do this, we take each player off of the field and re-run the predictions to see how big the magnitude of the change in catch probability is. The bigger the magnitude difference, the more credit that player gets. Then, we calculate the credit each defender gets with <span class="math inline">\(credit_{i} = \frac{min(d_{i}, 0)}{\sum_{i} min(d_{i}, 0)}\)</span> where <span class="math inline">\(d_{i}\)</span> is the catch probability without that player on the field minus the catch probability with him on the field. In other words, if one player gets <span class="math inline">\(75\%\)</span> of the credit for a play and the play is worth <span class="math inline">\(+.8\)</span> drops added, then that player gets <span class="math inline">\(.8 \cdot .75 = +.6\)</span> drops of credit, and the remaining <span class="math inline">\(+.2\)</span> drops is divvied up amongst the other defenders in the same fashion.</p>
</div>
<div id="target-probability" class="section level2">
<h2 class="hasAnchor">
<a href="#target-probability" class="anchor"></a>Target Probability</h2>
<p>Our target model is based around comparing the probabilities a receiver is targeted before the play begins and when the ball is thrown with the actual receiver targeted. We can use these probabilities to make estimates of how well the defender is covering (are receivers less likely to be thrown the ball because of the pre-throw work of a defensive back?) and how much respect they get from opposing offenses (do quarterbacks tend to make different decisions at throw time because of the defensive back?).</p>
<p>To determine the probability of a receiver being targeted before the play, we chose to take a naive approach. Each receiver on the field is assigned a “target rate” of <span class="math inline">\(\frac{targets}{\sqrt{plays}}\)</span>, which is then adjusted for the other receivers on the field and used as the only feature for a logit model. The idea of this rate was to construct a statistic which rewarded receivers for showing high target rates over a large sample, but also giving receivers who play more often more credit.</p>
<p>The model for target probability at the time of throw was a tree booster similar to the two catch probability models. This model used the positional data, comparing the receiver position to the QB and the three closest defenders along with a variety of situational factors such as the distance to the first down line, time left, weather conditions, how open that receiver is relative to others on the play to determine how likely that receiver is to be targeted.</p>
<p>The pre-snap model, which by design only considers the players on the field for the offense, performs relatively well for the lack of information with an AUC of <span class="math inline">\(0.59\)</span> and is well-calibrated on a held-out dataset. The pre-throw model performs much better given the extra information, with <span class="math inline">\(89\%\)</span> recall, <span class="math inline">\(94\%\)</span> precision, and <span class="math inline">\(0.94\)</span> AUC. Calibration plots of the models on held-out data are below.</p>
<p> </p>
<div class="figure" style="text-align: center">
<img src="../inst/plots/target_calplot_pre_snap.png" alt="Target Probability Model Calibration Plots" width="45%" height="45%"><img src="../inst/plots/target_calplot_calibrated.png" alt="Target Probability Model Calibration Plots" width="45%" height="45%"><p class="caption">
Target Probability Model Calibration Plots
</p>
</div>
<p> </p>
<p>We can estimate how a defensive back is impacting the decisions made by the quarterback through two effects. The first, comparing the target probability prior to the play to the target probability at the time of the throw is meant to estimate how well the receiver is covered on the play. For example, consider a receiver with a target probability of <span class="math inline">\(0.2\)</span> prior to the snap who ends up open enough to get a target probability of <span class="math inline">\(0.5\)</span> when the ball is thrown. This difference is attributed to the closest defensive back who would be credited with <span class="math inline">\(-0.3\)</span> coverage targets. If on the same play another receiver had a pre-snap target probability <span class="math inline">\(0.3\)</span> but a target probability of <span class="math inline">\(0\)</span> at throw time, the closest defensive back would be credited with <span class="math inline">\(+0.3\)</span> coverage targets. The other effect attempts to measure how the quarterback is deterred from throwing when that particular defensive back is in the area of the receiver by comparing the probability of a target to the actual result. So if a certain receiver has a target probability of <span class="math inline">\(0.6\)</span> at the time of the throw and isn’t targeted, the closest defender is credited with <span class="math inline">\(+0.6\)</span> deterrence targets.</p>
</div>
<div id="results" class="section level2">
<h2 class="hasAnchor">
<a href="#results" class="anchor"></a>Results</h2>
<p>Having produced these four models that gave us estimates of the influence of the defensive backs on a given play, we can accumulate the results over an entire season to produce an estimate of individual skill across the dimensions described by the models. As there is not a straightforward way to measure the relative value of these skills, we chose to combine the individual skill percentiles for each defender as a measure of their overall skill. With that as the estimate, these are our top 15 pass defending defensive backs in 2018:</p>
<div class="figure" style="text-align: center">
<img src="../inst/plots/final_leaderboard.png" alt="Top 15 Defenders, 2018" width="75%"><p class="caption">
Top 15 Defenders, 2018
</p>
</div>
<p>A full leaderboard of these can be found <a href="https://bdb-2021.herokuapp.com/">on our Shiny app</a> in the <code>Overall Rankings</code> tab. To help display these results and a few other metrics (such as how difficult the defensive assignment was based on pre-snap target probability and actual separation from receiver at throw time) we developed player cards for each qualifying defender. For example, this is our card for #1 defender Richard Sherman:</p>
<p><img src="../inst/plots/sherman_card.png" width="75%" style="display: block; margin: auto;"></p>
<p>These cards can also be found on our Shiny app under <code>Player Cards</code>.</p>
</div>
<div id="further-work" class="section level2">
<h2 class="hasAnchor">
<a href="#further-work" class="anchor"></a>Further Work</h2>
<p>There are a number of things that we didn’t consider or that would be interesting extensions of this project. Two clear ones are interceptions added and fumbles added, as those are hugely impactful football plays that can swing the outcomes of games. We also only considered raw changes in aggregating the player stats (i.e. targets prevented and drops added), but using EPA added instead would certainly be a better metric, since not all drops, for example, are created equal. In addition, it is not clear that a drop added is worth the same as a target deterred – an assumption we made – and EPA would help solve this problem too. It would also be interesting to test how similar our metrics are between seasons to confirm that our metrics are measuring the stable skill of a defender..</p>
</div>
<div id="appendix" class="section level2">
<h2 class="hasAnchor">
<a href="#appendix" class="anchor"></a>Appendix</h2>
<p>All of our code is hosted in two Github repos: <a href="https://github.com/hjmbigdatabowl/bdb2021">hjmbigdatabowl/bdb2021</a>, which hosts our modeling code, and <a href="https://github.com/hjmbigdatabowl/bdb2021-shiny">hjmbigdatabowl/bdb2021-shiny</a>, which hosts the Shiny app.</p>
<p>There is extensive documentation for our code on our <a href="https://hjmbigdatabowl.github.io/bdb2021/reference/">pkgdown site</a>.</p>
<p>The Shiny app can be found <a href="https://bdb-2021.herokuapp.com/">here</a>, which lets you explore our models, results, and player ratings.</p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Matt Kaye, Hugh McCreery.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
